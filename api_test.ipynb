{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyOJTdTv3Re9uVJ9/jG0EZCg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishesh711/AMS-560-Project-Testing/blob/main/api_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install assemblyai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2npTa8STBHE",
        "outputId": "cd7daf32-b591-4453-f627-ad48b22f0b99"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting assemblyai\n",
            "  Downloading assemblyai-0.34.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting httpx>=0.19.0 (from assemblyai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: pydantic!=1.10.7,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from assemblyai) (2.9.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7 in /usr/local/lib/python3.10/dist-packages (from assemblyai) (4.12.2)\n",
            "Collecting websockets>=11.0 (from assemblyai)\n",
            "  Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.19.0->assemblyai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.19.0->assemblyai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx>=0.19.0->assemblyai)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.19.0->assemblyai) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.19.0->assemblyai) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.19.0->assemblyai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.10.7,>=1.7.0->assemblyai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.10.7,>=1.7.0->assemblyai) (2.23.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.19.0->assemblyai) (1.2.2)\n",
            "Downloading assemblyai-0.34.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.6/72.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: websockets, h11, httpcore, httpx, assemblyai\n",
            "Successfully installed assemblyai-0.34.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 websockets-13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b8ZkOZVSxjS",
        "outputId": "f314a2dd-604b-4028-841d-8d60aa188eae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, let's continue from last time we talked about the milestones of AI, right? So the last part is that in 2016, Google DeepMind Africa AI defeated the cold war champion, Lsedo, right? So that was because the previous one, deep blue, is also. Yeah, I'm not old enough at that time, but this one actually, because I also play the game go. So it's also a big blow to myself, because before that game, people have long considered that the complexity of the game go, it's so high that it is really hard for a computer program to beat a human being. Actually, before AlphaGo, there are many other AI tools to play the game go, but the performance is so vague. So they are far away from beating human, even professional player. Not mentioning the world champion, right? But you can say actually during the game, it's actually really hard for Li Sido to find any opportunity. And after that, the master go and defeated Kuji, another world champion, very easily. And so very quickly that the Google the demand announced that they will no longer further improve it, because it's already better than all the human beings and the significant. So there is actually no chance for human to win at this time. So after that, you probably heard about the people talking about Turing test. So about ten years ago, AI somehow they passed train test computation, but that was not very convincing. Nowadays, I think the large angle model like Chai TBD already is much better and probably can pass the turn test medical lives, right. Robert passed national medical exam. Also here AIP, the human radiologist, after looking at those x ray image. So image area AI can do better than human doctors. That's one area the job can be replaced. Also the medical devices. Of course we can. Yeah, this is a part we probably want to add a little bit more of the new news. So let's come to this one. Let me share another screen. Okay, so three major tools for the larger model nowadays, if you are not familiar, why is Chai DBT the most recent version, the GPT 4.0. Google has Gemini, and there is another tool called Cloud AI. So my experience is that it's actually fairly good. So what I'm trying to ask is a question like, what are the mild dose of AI? Development of AI test since 2017? I can ask the same question for all the three AI tools, and then we can compare and also try to combine the message we can. So you can see, these are the result from TRBT 2018. There is something called Bert developed by Google. Actually, I think before that they have the 2017 they develop transformer. That's probably even more important. And for demand they develop alpha four. Alphafold is a very successful example to predict the pretend folding. So before the two, this was a big area of research, some word. Famous researchers published papers in Nature Science by just doing this one. And now it's almost completely replaced by Aihdenkhdev. Alpha fold can do better than AIB, the researcher. So actually that means those researchers are suddenly out of job, they don't have work to do. But for the society, this is a big advance because the AI to apply that in science exploration. So we only have a limited number of successes. This is one and 2019 they have GPT-2 and the Alpha star. Yeah, I should guide this one in the size. Later I will comment it as well. So today, now they have a gp two, even though gp two was not that famous. But it's under development. So the Alpha star is doing in a real time strategy game like Starcraft. And next year they have another two, the GPT-3 and Alpha phone two and 2021. That is darling. Darling is basically generated image instead of just the text. And they also have the code. You see, most of the development are found either OpenAI or demand. That is a situation, right? That the deepest, the major development nowadays are dominated by major a small number of companies. In 2022, I think something around the end of 2022, OpenAI released GPD 3.5. This is the first time that is a very powerful chatbot and quickly become a very useful one, very popular. It's less than two years from now, 32 and the GPD four the performance further improved. And you can see there are other tools like a cloud. Later we will see the performance there. And also Lama is from meta and it's an open source model. Before we go there, this is darling only can generate image. So we can ask it to generate an image of AI mile storms from. Let's see what we will get. It takes some time. Meanwhile, while waiting, we can look at Cloud AI, right? Cloud AI have a similar result, right? So, but you can see it's also a little bit different. So this lambda probably you still remember the news, right? So this lambda on Google employee feel like this is already kind of emotional, similar to human beings. So basically it was critical fire during Google. Later we have a tragic, right? And Google actually have another one, the Paul Allen. So it's a very large, you say 540 billion parameter language model, but the performance is not that good. The stable diffusion is a technology behind the darlingenheid and the GPT four is much better. The part going into Gemini. Right. So cloud also keep developing. So the column three now we are using now is very powerful multimodal AI. Now AI can not only just do text but they can do image and audio. So here actually you can directly say audio to it. Okay, so this is uh two. How do you like it? Yeah, this one is not that good, right. But this one seems better, you know, but it's also the number are not that good. So this is an area they can further improve. Finally, let's see the answer from Gemini Gemny gave us answer, right. Alpha. Go zero. Right. Okay. From here you can see some preference, right. Some buyers. So each company's two is certainly biased towards a product of that company, Alpha. Right. Lambda. So different tools. Okay. Yes, darling. Yeah, the text is darling and also is video generation tools. Right. So also this is very hard I think what's the name of the company? So last year there was a very, let me see. So maybe I can find it for you guys. This remind me that. What's that it. Yeah, I just forgot the name. Anyone can remind me. Here was a. What is that? Yeah, somebody says going deeper. No, that's. Yeah, yeah. Nevermind. So basically the reason. Yeah, Sora. Yes. Yeah. Thank you. So let's see what's sora currently doing? Sora is part of OpenAI, but the reason I want to mention this one because even for Sora, for all those video generating also how to handle text is a big issue because here if you look at the traditional ones, like an image, right. So even though there may be some issues right in the background, right. So we cannot tell. But if there is some word there, some text there, we can easily tell whether it is good or bad. Right. Like this one. Right. For other part you feel good, but for the text you can easily see the issues. Okay. This is also because they didn't use a separate text generator for the text, I think that's the root cause of the issue. Okay, let's come back. Okay, so with all those great improvement, right, so what I want to share with you the, the slides, right, showing here. So this is how the technology changes over time. So the first stage is called technology trigger. So you start from RDD and then you go to the startup company, first round of vc funding and you get the first generation product, high price, lot of issues and then you get the early adopters. But at this time, because this is a new technology, you start to have mass media types. So that is the issue, right. Because the media report, right. Is kind of positive feedback. Loop. Whenever they say something, they start to make it larger, larger. Also they say how rumor on the social media network or even our in person, the rumor will keep going into the extreme case. That's culturally the reason start to create this kind of peak of inflated expectation, right? So like while the technology is keep improving, right? Maybe it's a line like this, right? But the problem is that the after some time, the expectation is much higher than what the technology really is. So that's why after a while. So where is at the peak that is the most dangerous period, right? Because the technology cannot meet the expectation. And then once it starts, people realize, okay, we cannot deliver the expectation. Actually the technology is still developing very well over time, but it's just our expectation can go really high. That is the issue. We start to have the negative press and a lot of failures. Then you need a second round of research. And then you go to the disillusionation part where people get very frustrated. And then we go to the second generation of product, it's better. And at this time, not many people care about this one, but it keeps increasing until a point suddenly people realize, okay, the third generation or even the fourth 5th generation is good enough. Let's actually go to the stage that it works well. But you may go to several kind of listen up and down cycle before you reach the productivity stage. And also this change a lot. People are very bad at doing this prediction. Let's look at this one. This one is the Gartner. It's probably the most famous company doing this prediction every year. So they have the hyper cycle for emerging technology. They release it every year. This is what I have in business seven years ago. So at that time you can say we consider VR as already here, but after seven years, VR still not that close. Yeah. There are some videos on YouTube that you can watch using VR technology. But other than that, the major development of AR, like the Apple's headset, the vision Pro actually stopped. It's actually longer than we expected. VR and VR, meanwhile, the peak they talk about is deep learning or machine learning. So those one, those are great. It's actually the case. It's there. Edge computing. Still not sure, right? So another technology there, let me see. 5g is a technology that is probably. There may be some issue, right? Because originally 5g promised a lot of good stuff, but it's actually not that easy to deliver. But currently, maybe you feel like you probably didn't feel the change from four g to five g, right? It's just maybe the speed is a little bit higher, but that's all on the other side. 4d printing, I have no idea where it is now. ATI is also far from. It's more than ten years, right? Deep reinforcement. Malaria is not bad. Quantum computing they consider also far, but it's actually developed fast. Developed very fast. This blockchain. And at the year 2017, they consider blockchain already going down. But later, you know that from 2017 until now, the blockchain technology developed a lot, including the cryptocurrency. So basically, I show you guys this one. So some of them are right, but some may not be, many of them may be wrong, but you can also say, oh, it changed quickly, year from year, right? You may expect those technologies stay there and adjust, slowly move, but it's not the case. So this is the one for 2018, but some technology no longer there, right? For example, where is VR? VR in the previous is here, right? We expect to be a little bit, but we didn't see it. Others, like deep learning is still here, even though it actually goes back a little bit. I don't know how that can go back. But anyway, 5g is here, seems promising, but still. And AGI 4D, right? So some technology is still there, but they have something new. Right. Where is autonomy driving? Level four. Right. They put here. And yeah, that is still very hard for automobile driving. Okay. This is 2018, this is 19. So 2019, you can say the peak, but the 5g now still we are the AR. They all disappear. Right? So here, explainable. AI start to be here. Right? Low Earth orbit silicism, like the starting some other ones. Right? But I should tell you, I found what they say. During this time period, we already have GPD two. Right? But from here, you say nowhere, anywhere we have something like this. No. Right. Basically they didn't realize that as well. So even though they have a lot of AI, but now the AI is like the large language models related, right? Even generative. So at that time, they still talk about the generative adversary network, the gut, not the generative. Aih, but this is 2020, similar. But here, finally they have this generative AI. Also self visualized learning become important. They discuss metadata. Right? But where is the blockchain? I didn't see it, but this is a year actually, bitcoin become very important. And all those cryptocurrency based on the smart contract also become popular. But you said it didn't have anything here. But the next year they start to have something called non fungible tokens. NFT. But if you know the history later, next year. That one goes nowhere. Almost sorry. This is a stop at 2021. Let me give you what happened after that so we can look at 2021. We already have 2022. This is from 2022 you can say, right? So this one NFT goes down, right? But generative AI at the year 2020 is actually at the beginning, right? So because 2023 there is a big jump from the TRBT. But you say.\n"
          ]
        }
      ],
      "source": [
        "# `pip3 install assemblyai` (macOS)\n",
        "# `pip install assemblyai` (Windows)\n",
        "\n",
        "import assemblyai as aai\n",
        "\n",
        "aai.settings.api_key = \"9c38e20bc2844451874064c955d8f2fe\"\n",
        "transcriber = aai.Transcriber()\n",
        "\n",
        "transcript = transcriber.transcribe(\"/content/hamp.mp4\")\n",
        "# transcript = transcriber.transcribe(\"./my-local-audio-file.wav\")\n",
        "\n",
        "print(transcript.text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I4sI4UXsTAKw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}